# A Spencer-Brown Inspired Ontological Model of Ruha Benjamin's "Race After Technology"

This report presents a structured ontological index of Ruha Benjamin's influential 2019 work "Race After Technology: Abolitionist Tools for the New Jim Code" using Spencer-Brown's calculus of distinctions. By marking entities as distinctions (◻) and relationships as indications (→), we create a formal representation that illuminates the book's key arguments about technology's role in perpetuating racial hierarchies.

## Primary Entities and Foundational Distinctions

### Core Theoretical Constructs

◻ **Race After Technology**: Benjamin's 2019 book examining discriminatory design in technology[1]

◻ **New Jim Code**: Benjamin's central theoretical framework describing discriminatory designs that encode inequity[2][5][6]

◻ **discriminatory design**: Technology design that encodes inequality through seemingly neutral systems[1][5]

◻ **race as technology**: Conceptualization of race itself as a tool designed to stratify and sanctify social injustice[6][7]

◻ **abolitionist tools**: Conceptual frameworks offered to counter discriminatory design[5][7]

◻ **race neutrality**: A destructive force that masks how technologies reproduce inequalities[5]

◻ **race critical code studies**: The hybrid literature in which Benjamin situates her work[5]

### Forms of Discriminatory Design

◻ **explicit hierarchical amplification**: Discriminatory designs that overtly amplify racial hierarchies[2][5][6]

◻ **default replication**: Designs that ignore but thereby replicate social divisions[2][5][6]

◻ **failed bias fixes**: Technologies aiming to fix racial bias but doing the opposite[2][5][6]

◻ **coded bias**: Discrimination embedded within technological systems[4][5]

◻ **imagined objectivity**: The perceived neutrality of technologies that masks their bias[5]

## Morphisms and Relational Structures

### Theoretical Relationships

◻ **New Jim Code** → *comprises* → ◻ **range of discriminatory designs**
   *Different types of discriminatory designs that work in various ways to encode inequity*[2][5][6]

◻ **race** → *functions as* → ◻ **technology**
   *Race itself operates as a technology designed to stratify social injustice*[6][7]

◻ **technology** → *appears as* → ◻ **neutral and benevolent**
   *Technology presents itself as objective while hiding discrimination*[2][5][7]

◻ **Race After Technology** → *provides* → ◻ **conceptual tools**
   *The book offers tools to decode tech promises with sociological skepticism*[4][5][7]

◻ **New Jim Code** → *enables* → ◻ **social containment**
   *Innovation that maintains social control while appearing fairer than previous eras*[5]

◻ **coded bias** + ◻ **imagined objectivity** → *produces* → ◻ **New Jim Code**
   *The combination creates a system that hides the nature of domination*[5]

### Technological Impact Relationships

◻ **technology** → *can hide, speed, and deepen* → ◻ **discrimination**
   *Technology has the potential to conceal and accelerate discriminatory practices*[2][5][6]

◻ **automation** → *reinforces* → ◻ **White supremacy**
   *Automated systems can deepen social inequity while appearing neutral*[5][7]

◻ **technologies** → *reinforce and deepen* → ◻ **societal inequities**
   *Tech systems amplify existing social divisions rather than resolving them*[1][3]

◻ **race neutrality** → *functions as* → ◻ **deadly force**
   *The apparent neutrality of technology enables harm to marginalized communities*[5]

## Empirical Examples and Case Studies

### Documented Instances of Discriminatory Design

◻ **gang database** → *exhibits* → ◻ **discriminatory design**
   *A database that is 87% Black and Latinx, including babies under age 1*[1]

◻ **beauty contest algorithm** → *exhibits* → ◻ **discriminatory design**
   *A robot-judged contest where all winners were white with only one dark-skinned finalist*[1]

◻ **recidivism risk algorithm** → *exhibits* → ◻ **discriminatory design**
   *An algorithm more likely to wrongly flag Black defendants as future criminals*[1]

◻ **Google Maps glitch** → *exhibits* → ◻ **discriminatory design**
   *Software reading "Malcolm X Boulevard" as "Malcolm Ten Boulevard"*[1]

◻ **automated soap dispenser** → *exhibits* → ◻ **infrared technology bias**
   *A device that wouldn't work with darker skin because it absorbs more light*[4]

## Conceptual Extensions and Applications

### Institutional Connections

◻ **criminal justice system** → *employs* → ◻ **risk assessment tools**
   *Institutions outsourcing human decisions to potentially biased technologies*[4]

◻ **healthcare system** → *employs* → ◻ **risk assessment tools**
   *Medical institutions using technologies that may encode discriminatory practices*[4]

◻ **education system** → *employs* → ◻ **risk assessment tools**
   *Educational institutions deploying technologies with potential hidden biases*[4]

### Methodological Approaches

◻ **Just Data Lab** → *is founded by* → ◻ **Ruha Benjamin**
   *Research lab examining data discriminations and developing tools for justice*[5]

◻ **Race After Technology** → *analyzes* → ◻ **tech industry hype**
   *The book cuts through promotional claims to reveal discriminatory realities*[5][7]

◻ **race critical code studies** → *informs* → ◻ **New Jim Code concept**
   *The theoretical approach examining how race and racism enter technological processes*[5]

## Conclusion

This Spencer-Brown inspired ontological model captures the rich conceptual architecture of Benjamin's "Race After Technology." Through formal distinctions (◻) and indications (→), we visualize how Benjamin analyzes the ways in which ostensibly neutral technologies can embed and amplify racial hierarchies. The structured index highlights Benjamin's central contribution: exposing the "New Jim Code" as a set of discriminatory designs that encode inequity while appearing objective and progressive, while also offering abolitionist tools to contest these systems.

Citations:
[1] https://www.princeton.edu/news/2020/05/15/benjamins-race-after-technology-speaks-growing-concern-among-many-tech-bias
[2] https://www.youtube.com/watch?v=aMuD_lAy2zQ
[3] https://ephemerajournal.org/contribution/biased-robots-race-technology
[4] https://www.youtube.com/watch?v=rY8RkET3KC0
[5] https://listen.datasociety.net/episodes/race-after-technology/transcript
[6] https://scijust.ucsc.edu/2019/10/16/oct-16-ruha-benjamin/
[7] https://www.wiley.com/en-us/Race+After+Technology:+Abolitionist+Tools+for+the+New+Jim+Code-p-9781509526437
[8] https://livrepository.liverpool.ac.uk/3101665/1/Spencer%20Brown%20submission%20(1)%20(1).pdf

---
Answer from Perplexity: https://www.perplexity.ai/search/sts-ms-cat-core-26eOjT2rQjiRqIxKt6q3GA?utm_source=copy_output