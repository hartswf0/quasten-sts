<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Noble - Algorithms of Oppression (Analysis)</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <h1>Noble - Algorithms of Oppression (Analysis)</h1>
    <a href="index.html">Back to Index</a>
  </header>
  
  <main>
    <p>id: 202405201034</p>
    <p>title: Noble - Algorithms of Oppression (Analysis)</p>
    <p>tags: <span class="olog-relation">[sts, critical-race-theory, algorithms, search-engines, bias, racism, sexism, platforms, olog-analysis]</span></p>

    <p><strong>Reference:</strong> Noble, Safiya - Algorithms of Oppression: How Search Engines Reinforce Racism (2018)</p>

    <p><strong>Focused Problem Statement:</strong></p>
    <p>Commercial search engines like Google (Level 1 Machine) present their ranked results as objective, neutral, and authoritative reflections of information relevance about the world (Level 0 Reality). This framing (Level 3 Platform Claims) systematically obscures how their core algorithms, driven by advertising models and trained on societally biased data, actively generate racist and sexist representations ("Algorithms of Oppression"). These outputs harm marginalized groups (Level 2 User Experience) and shape public knowledge by naturalizing systemic biases as mere reflections of popularity or query patterns (Level 4 Logic: Obscuring Bias via Neutrality Claims).</p>
    <h2>1. Core Model and Index</h2>

    <p>Noble, S. (2018). Algorithms of oppression: How search engines reinforce racism. NYU Press.</p>

    <p>MODEL: Argues that commercial search engines, particularly Google, are not neutral information sources but biased platforms whose algorithms perpetuate harmful stereotypes, racism, and sexism ("algorithms of oppression"), reflecting and amplifying societal inequalities under the guise of objective ranking.</p>

    <p>Index:</p>

    <p><span class="distinction"><span class="symbol">◻</span> Search Engine Algorithms </span><span class="arrow">→</span> (are not neutral but) <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> Biased / Oppressive</span></p>

    <p><span class="distinction"><span class="symbol">◻</span> Algorithmic Bias </span><span class="arrow">→</span> (reinforces) <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> Racism / Sexism / Social Inequalities</span></p>

    <p><span class="distinction"><span class="symbol">◻</span> Information Environment </span><span class="arrow">→</span> (is shaped by) <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> Commercial Interests / Algorithmic Decisions</span></p>

    <p><span class="distinction"><span class="symbol">◻</span> Objectivity (of search results) </span><span class="arrow">→</span> (is a) <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> Myth / Veneer</span></p>
    <h2>2. Four-Level Analysis</h2>
    <p><strong>Illustrative Olog Analysis (Google Search for "black girls"):</strong></p>

    <ul>
      <li><span class="level-heading"><strong>Level 0: Base World</strong></span></li>
    </ul>
    <p>    * <code>&lt;Reality&gt;</code> = <code>&lt;Diverse experiences, identities, realities of Black girls&gt;</code></p>

    <ul>
      <li><span class="level-heading"><strong>Level 1: Machine Layer</strong></span></li>
    </ul>
    <p>    * <code>&lt;Google Search Algorithm&gt;</code> <code><span class="olog-relation">[simulates]</span></code> <span class="arrow">→</span> <code>&lt;Model of Relevance biased by link popularity, commercial value, existing racist/sexist web content&gt;</code> <strong>(Problem: Model misrepresents Level 0, amplifies bias).</strong></p>
    <p>    * <code>&lt;Algorithm&gt;</code> <code><span class="olog-relation">[outputs]</span></code> <span class="arrow">→</span> <code>&lt;Ranked SERP historically dominated by pornography/stereotypes&gt;</code> <strong>(Problem: Harmful output presented as neutral/authoritative).</strong></p>
    <p>    * <code>&lt;Algorithmic Logic/Ad Model&gt;</code> <code><span class="olog-relation">[filters]</span></code> <span class="arrow">→</span> <code>&lt;Web, amplifying biased/commercially valuable content&gt;</code> <strong>(Problem: Filtering reinforces oppression).</strong></p>

    <ul>
      <li><span class="level-heading"><strong>Level 2: Human Use Layer</strong></span></li>
    </ul>
    <p>    * <code>&lt;Users (searchers)&gt;</code> <code><span class="olog-relation">[interpret]</span></code> <span class="arrow">→</span> <code>&lt;Results as reflecting reality or authoritative info&gt;</code> <strong>(Problem: User perception shaped by biased output).</strong></p>
    <p>    * <code>&lt;Content Creators (SEO/Porn Industry)&gt;</code> <code><span class="olog-relation">[steer]</span></code> <span class="arrow">→</span> <code>&lt;Content to exploit biased search patterns&gt;</code></p>
    <p>    * <code>&lt;Google&gt;</code> <code><span class="olog-relation">[claims/frames]</span></code> <span class="arrow">→</span> <code>&lt;Neutrality, reflecting 'what's on the web'&gt;</code></p>

    <ul>
      <li><span class="level-heading"><strong>Level 3: Reflexive Framing Layer</strong></span></li>
    </ul>
    <p>    * <code>&lt;Noble (Theorist)&gt;</code> <code><span class="olog-relation">[models]</span></code> <span class="arrow">→</span> <code>&lt;Search as "Algorithms of Oppression"&gt;</code> / <code><span class="olog-relation">[questions]</span></code> <span class="arrow">→</span> <code>&lt;Platform neutrality claims&gt;</code></p>
    <p>    * <code>&lt;Platform's Self-Framing&gt;</code> <code><span class="olog-relation">[models]</span></code> <span class="arrow">→</span> <code>&lt;Search as objective information retrieval service&gt;</code></p>

    <ul>
      <li><span class="level-heading"><strong>Level 4: Latent & Systemic Evaluation</strong></span></li>
    </ul>
    <p>    * <code>&lt;Algorithmic Objectivity Myth (Logic)&gt;</code> <code><span class="olog-relation">[obscures]</span></code> <span class="arrow">→</span> <code>&lt;Encoded bias, commercial drivers, representational harms&gt;</code> <strong>(Problem: Core logic masks discriminatory function).</strong></p>
    <p>    * <code>&lt;Ad-Based Platform Economics (Disposition)&gt;</code> <code><span class="olog-relation">[naturalizes]</span></code> <span class="arrow">→</span> <code>&lt;Prioritizing engagement/profit over information justice&gt;</code></p>
    <p>    * <code>&lt;Algorithms of Oppression Framework&gt;</code> <code><span class="olog-relation">[reframes]</span></code> <span class="arrow">→</span> <code>&lt;Biased results as systemic feature linked to power&gt;</code> / <code><span class="olog-relation">[elevates]</span></code> <span class="arrow">→</span> <code>&lt;Critique from LIS/Critical Race perspectives&gt;</code></p>
    <h2>3. Spatiotemporal Framework</h2>


    <p>34. Noble, Safiya - Algorithms of Oppression (2018)</p>

    <div class="spatiotemporal">
      <div class="spatiotemporal-title">SPATIOTEMPORAL FRAMEWORK</div>
    <p><span class="distinction"><span class="symbol">◻</span> SPATIOTEMPORAL UNIVERSE</span>: Contemporary digital information environment dominated by commercial search engines, especially Google.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Contains]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> FIELD</span>: Commercial search engine operations: data collection, indexing, algorithmic ranking, advertising integration, user interaction.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Has]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> DOMAIN</span>: Search algorithms × Platform architecture × Advertising models × User queries & data × Societal biases (racism, sexism) × Time (evolution of search & bias).</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Projects]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> SIGNAL</span>: Search engine results pages (SERPs), keyword associations, autocomplete suggestions, advertising placements, biased representations, data traces of user behavior reflecting/shaping bias. (ℝᵏ representing ranking scores, ad frequencies, measures of stereotypical representation).</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Admits]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> PERTURBATION</span>: Algorithm updates (often opaque), public critique and pressure, changes in advertising policies, shifts in user search behavior, alternative search engines.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Observed Through]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> WINDOW</span>: Critical Race Theory, Feminist STS, Library & Information Science (LIS), Critical Political Economy of Media/Platforms.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Defines]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> OBSERVATION SCALE</span>: Analysis of specific search query results, platform design choices, advertising logic, and their connection to systemic inequalities.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Delimits]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> CONTEXT BOUNDARY</span>: Focuses on the inherent bias within commercial search architecture, challenging claims of neutrality and objectivity; centers impacts on marginalized groups (esp. women of color).</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Generates]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> SAMPLING LATTICE</span>: Analysis of problematic search results for queries related to race and gender (e.g., "black girls"), examination of Google's AdSense logic, critique of PageRank's assumptions.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Manifests As]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> PHENOMENON</span>: "Algorithms of Oppression" – Commercial search engines, far from being neutral, systematically produce biased, racist, and sexist results that reflect and amplify societal inequalities, driven by their ad-based economic models and encoded assumptions.</p>

    <p><span class="distinction"><span class="symbol">◻</span> ENGINE</span>: Critical Analysis of Search Platforms and Results.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Applies]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> TRANSFORM</span>: Deconstructing the 'neutrality' myth by linking specific biased search outputs to the underlying algorithmic logic, data inputs, economic incentives, and societal contexts.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Operates On]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> PATCH</span>: Specific search query results, autocomplete suggestions, advertising patterns, or platform policy statements (e.g., results for racialized or gendered terms).</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Produces]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> INVARIANT</span>: The pattern of search results reinforcing harmful stereotypes; the identification of platform logic (prioritizing popularity/profit) as a source of bias; the concept of "technological redlining."</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Requires]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> CONTRACTION</span>: Focusing on the intersection of algorithmic processes, commercial interests, and societal power structures (race, gender).</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Constructs]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> REPRESENTATION</span>: A model of search engines as powerful actors actively shaping public knowledge in biased ways; critique of algorithmic objectivity; the framework of "Algorithms of Oppression."</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Optimizes]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> RECURSION</span>: Feedback loops where biased search results shape user perceptions and online content creation, which then feeds back into the algorithm's data, further entrenching bias.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Embeds]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> MODEL</span>: Critical Race Theory, feminist media studies, LIS principles (information access, ethics), political economy of communication, STS (bias in design).</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Projects]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> METRIC</span>: Degree of harmful stereotyping in results, evidence of disparate impact based on race/gender, influence of commercial interests on information quality (qualitative critical analysis).</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Seeks]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> FIXED POINT</span>: Recognition of commercial search engines as inherently biased systems participating in oppression, demanding critical scrutiny and regulation.</p>

    <div class="metamodel-box">
      <div class="metamodel-title">METAMODEL</div>

    <p>Distinctions & Crossings:</p>

    <p><span class="distinction"><span class="symbol">◻</span> MODEL (Platform's claim of neutrality/objectivity/algorithmic authority) | ◻ REALITY (The biased, harmful, and stereotypical results produced, reflecting and shaping social inequalities) </span><span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> MEASUREMENT ARTIFACT (The specific search results pages (SERPs) that demonstrate racist/sexist representations; user experiences of informational harm).</span></p>

    <p><span class="distinction"><span class="symbol">◻</span> TIME-LIKE (Historical development of racial/gender biases; evolution of search algorithms) | ◻ SPACE-LIKE (The structure of the algorithm, database, advertising system at a given time) </span><span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> CAUSAL CONE (How historical societal biases are encoded into the platform's current structure (space-like), shaping information access and perpetuating harm over time).</span></p>

    <p><span class="distinction"><span class="symbol">◻</span> CONTINUOUS (Spectrum of information quality/human identity) | ◻ DISCRETE (Ranked list of search results, algorithmic classifications, ad categories) </span><span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> SAMPLING THRESHOLD (The algorithmic ranking and selection process that surfaces specific discrete results, often amplifying biased or low-quality content based on popularity or ad revenue potential).</span></p>

    <p>Operations: <span class="olog-relation">[Observe]</span> search engine results, platform features, advertising. <span class="olog-relation">[Encode]</span> observations using CRT, feminist theory, LIS ethics to identify bias and harm. <span class="olog-relation">[Convolve]</span> user queries (PATCH) with platform's algorithmic/economic logic (KERNEL) to explain oppressive outputs (FEATUREs). <span class="olog-relation">[Entangle]</span> search technology with systems of racism, sexism, and capitalism. <span class="olog-relation">[Forget]</span> claims of algorithmic neutrality or objectivity made by platforms.</p>
    </div>
    </div>
  </main>
  
  <footer>
    <p><a href="index.html">Back to Index</a></p>
  </footer>
</body>
</html>
