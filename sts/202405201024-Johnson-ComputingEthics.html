<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Johnson - Computing Ethics (Analysis)</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <h1>Johnson - Computing Ethics (Analysis)</h1>
    <a href="index.html">Back to Index</a>
  </header>
  
  <main>
    <p>id: 202405201024</p>
    <p>title: Johnson - Computing Ethics (Analysis)</p>
    <p>tags: <span class="olog-relation">[sts, ethics, computing, technology, applied-ethics, policy-vacuum, olog-analysis]</span></p>

    <p><strong>Reference:</strong> Johnson, Deborah - Computing Ethics (4th ed.) (2009)</p>

    <p><strong>Focused Problem Statement:</strong></p>
    <p>The rapid development and deployment of computing technologies often create novel situations or significantly alter existing practices (Level 0 Reality transformed), leading to "policy vacuums" where existing ethical norms and legal frameworks (Level 1 Models applied) are inadequate or ambiguous. A purely technical or functionalist framing of these technologies (Level 3 Framing possibility) obscures their inherent ethical dimensions and the need for proactive ethical analysis. Johnson's work aims to bridge this gap by applying and adapting established ethical theories (Level 1 Ethical Models) to analyze specific computing dilemmas (Level 2 Use Cases) and identify ethically salient features (Level 4 Logic: Need for Applied Ethics).</p>
    <h2>1. Core Model and Index</h2>

    <p>Johnson, D. (2009). Computing ethics (4th ed.). Pearson.</p>

    <p>MODEL: Provides a framework for analyzing ethical issues arising from computing technology, covering topics like privacy, intellectual property, security, responsibility, and the digital divide, applying traditional ethical theories (utilitarianism, deontology) and developing concepts specific to the socio-technical impacts of computing.</p>

    <p>Index:</p>

    <p><span class="distinction"><span class="symbol">◻</span> Computing Technology </span><span class="arrow">→</span> (raises) <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> Unique Ethical Issues</span></p>

    <p><span class="distinction"><span class="symbol">◻</span> Ethical Frameworks (Utilitarianism, Deontology etc.) </span><span class="arrow">→</span> (can be applied to) <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> Computing Contexts</span></p>

    <p><span class="distinction"><span class="symbol">◻</span> Key Issues (Privacy, IP, Security, Responsibility) </span><span class="arrow">→</span> (are central to) <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> Computing Ethics</span></p>

    <p><span class="distinction"><span class="symbol">◻</span> Socio-technical Systems </span><span class="arrow">→</span> (are the locus of) <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> Ethical Analysis</span></p>
    <h2>2. Four-Level Analysis</h2>
    <p><strong>Illustrative Olog Analysis (Ethics of Online Privacy / Social Media Data Use):</strong></p>

    <ul>
      <li><span class="level-heading"><strong>Level 0: Base World</strong></span></li>
    </ul>
    <p>    * <code>&lt;Reality&gt;</code> = <code>&lt;Individual's personal information, Social interactions, Expectations of privacy&gt;</code></p>

    <ul>
      <li><span class="level-heading"><strong>Level 1: Machine Layer</strong></span></li>
    </ul>
    <p>    * <code>&lt;Social Media Platform Architecture&gt;</code> <code><span class="olog-relation">[simulates]</span></code> <span class="arrow">→</span> <code>&lt;Model designed for data collection, sharing, targeted advertising&gt;</code> <strong>(Problem: Technical design has inherent ethical implications for privacy).</strong></p>
    <p>    * <code>&lt;Platform&gt;</code> <code><span class="olog-relation">[outputs]</span></code> <span class="arrow">→</span> <code>&lt;User profiles, aggregated data, targeted ads, potential data breaches&gt;</code></p>
    <p>    * <code>&lt;Platform Terms/Interface Design&gt;</code> <code><span class="olog-relation">[filters/frames]</span></code> <span class="arrow">→</span> <code>&lt;User understanding and control over data sharing (often obscurely)&gt;</code> <strong>(Problem: Interface design affects ethical outcome).</strong></p>
    <p>    * <strong>(Alternative Level 1):</strong> <code>&lt;Ethical Theories (Utilitarianism, Deontology)&gt;</code> <code><span class="olog-relation">[simulate]</span></code> <span class="arrow">→</span> <code>&lt;Models for evaluating right/wrong action&gt;</code></p>

    <ul>
      <li><span class="level-heading"><strong>Level 2: Human Use Layer</strong></span></li>
    </ul>
    <p>    * <code>&lt;Users&gt;</code> <code><span class="olog-relation">[steer/share]</span></code> <span class="arrow">→</span> <code>&lt;Personal information, often without full awareness of implications&gt;</code></p>
    <p>    * <code>&lt;Platform Company&gt;</code> <code><span class="olog-relation">[interprets/uses]</span></code> <span class="arrow">→</span> <code>&lt;Data for commercial purposes&gt;</code></p>
    <p>    * <code>&lt;Ethicists/Policymakers&gt;</code> <code><span class="olog-relation">[interpret]</span></code> <span class="arrow">→</span> <code>&lt;Situation using ethical frameworks&gt;</code></p>

    <ul>
      <li><span class="level-heading"><strong>Level 3: Reflexive Framing Layer</strong></span></li>
    </ul>
    <p>    * <code>&lt;Johnson (Theorist/Ethicist)&gt;</code> <code><span class="olog-relation">[models]</span></code> <span class="arrow">→</span> <code>&lt;Computing issues via Applied Ethical Analysis&gt;</code> / <code><span class="olog-relation">[identifies]</span></code> <span class="arrow">→</span> <code>&lt;"Policy Vacuums" needing ethical deliberation&gt;</code></p>
    <p>    * <code>&lt;Techno-Utopian/Functionalist Framing&gt;</code> <code><span class="olog-relation">[models]</span></code> <span class="arrow">→</span> <code>&lt;Platform primarily as communication tool, downplaying ethical risks&gt;</code></p>

    <ul>
      <li><span class="level-heading"><strong>Level 4: Latent & Systemic Evaluation</strong></span></li>
    </ul>
    <p>    * <code>&lt;Novelty/Malleability of IT (Logic)&gt;</code> <code><span class="olog-relation">[obscures]</span></code> <span class="arrow">→</span> <code>&lt;How existing ethical principles apply or need adaptation&gt;</code> <strong>(Problem: Technology outpaces established norms).</strong></p>
    <p>    * <code>&lt;Commercial Imperatives (Disposition)&gt;</code> <code><span class="olog-relation">[naturalizes]</span></code> <span class="arrow">→</span> <code>&lt;Data collection practices that conflict with privacy values&gt;</code></p>
    <p>    * <code>&lt;Applied Computing Ethics Framework&gt;</code> <code><span class="olog-relation">[reframes]</span></code> <span class="arrow">→</span> <code>&lt;Technical design/use as inherently ethical domain&gt;</code> / <code><span class="olog-relation">[elevates]</span></code> <span class="arrow">→</span> <code>&lt;Need for explicit ethical analysis in socio-technical systems&gt;</code></p>
    <h2>3. Spatiotemporal Framework</h2>


    <p>24. Johnson, Deborah - Computing Ethics (4th ed.) (2009)</p>

    <div class="spatiotemporal">
      <div class="spatiotemporal-title">SPATIOTEMPORAL FRAMEWORK</div>
    <p><span class="distinction"><span class="symbol">◻</span> SPATIOTEMPORAL UNIVERSE</span>: Societies where computing technologies are prevalent and create novel ethical dilemmas.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Contains]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> FIELD</span>: Ethical issues arising from the development, deployment, and use of computer and information technologies.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Has]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> DOMAIN</span>: Technological capabilities (data processing, networking, AI) × Social practices impacted by tech × Existing ethical/legal frameworks × Stakeholder interests × Time (as tech evolves).</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Projects]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> SIGNAL</span>: Privacy violations, intellectual property disputes, security breaches, algorithmic bias, automation impacts on employment, accessibility issues, questions of responsibility for system failures. (ℝᵏ representing types of ethical harms, frequencies of issues, legal precedents).</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Admits]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> PERTURBATION</span>: New technologies (AI, IoT, social media), new laws/regulations (GDPR), emergence of new social norms around tech use, major ethical scandals.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Observed Through]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> WINDOW</span>: Applied Ethics methodology, drawing on traditional ethical theories (utilitarianism, deontology, virtue ethics) and developing concepts specific to socio-technical contexts.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Defines]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> OBSERVATION SCALE</span>: Focus on specific ethical dilemmas and principles related to computing, often analyzed through case studies.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Delimits]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> CONTEXT BOUNDARY</span>: Primarily focuses on applying established ethical frameworks to computing, identifying unique features ('policy vacuums,' malleability); less focused on radical critique of technology itself.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Generates]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> SAMPLING LATTICE</span>: Analysis of ethical issues concerning privacy, property, security, accountability, professional responsibility, freedom of speech online, digital divide.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Manifests As]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> PHENOMENON</span>: Computing technology as posing unique ethical challenges due to its logical malleability, scale, speed, and impact on social institutions, requiring careful application and sometimes adaptation of ethical principles.</p>

    <p><span class="distinction"><span class="symbol">◻</span> ENGINE</span>: Applied Ethical Analysis for Computing.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Applies]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> TRANSFORM</span>: Analyzing specific computing-related situations or technologies through the lens of established ethical theories and principles to identify obligations, rights, and potential harms.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Operates On]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> PATCH</span>: A specific case study involving computing ethics (e.g., a data breach, a biased algorithm, a software copyright issue).</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Produces]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> INVARIANT</span>: Identification of relevant ethical principles (privacy, autonomy, justice, responsibility); assessment of actions/policies according to those principles.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Requires]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> CONTRACTION</span>: Abstracting the ethically salient features from the technical and social details of the case.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Constructs]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> REPRESENTATION</span>: Frameworks for ethical decision-making in computing contexts; analyses of key ethical concepts (privacy, property etc.) as they relate to technology.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Optimizes]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> RECURSION</span>: Applying ethical analysis iteratively as technology and its societal impacts evolve, refining understanding and principles.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Embeds]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> MODEL</span>: Utilitarianism, Deontology (Kantian ethics), Virtue Ethics, Social Contract Theory, theories of justice.</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Projects]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> METRIC</span>: Consistency with ethical principles, respect for rights, fairness of outcomes, assignment of responsibility (normative ethical judgment).</p>

    <p><span class="arrow">→</span> <span class="olog-relation">[Seeks]</span> <span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> FIXED POINT</span>: Clear ethical guidance and reasoned justification for action in specific computing-related dilemmas.</p>

    <div class="metamodel-box">
      <div class="metamodel-title">METAMODEL</div>

    <p>Distinctions & Crossings:</p>

    <p><span class="distinction"><span class="symbol">◻</span> MODEL (Ethical theories/principles) | ◻ REALITY (Complex socio-technical situations and their consequences) </span><span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> MEASUREMENT ARTIFACT (Ethical judgments, policy recommendations, codes of conduct derived from applying the models to reality).</span></p>

    <p><span class="distinction"><span class="symbol">◻</span> TIME-LIKE (Evolution of technology and associated ethical norms/laws) | ◻ SPACE-LIKE (The structure of ethical theories and principles) </span><span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> CAUSAL CONE (How established ethical principles (space-like) are applied to and sometimes challenged or modified by evolving technological realities over time).</span></p>

    <p><span class="distinction"><span class="symbol">◻</span> CONTINUOUS (Spectrum of possible actions/outcomes) | ◻ DISCRETE (Ethical judgments - right/wrong, permissible/impermissible; distinct rights/principles) </span><span class="arrow">→</span> <span class="distinction"><span class="symbol">◻</span> SAMPLING THRESHOLD (The application of ethical rules or frameworks to categorize actions and outcomes).</span></p>

    <p>Operations: <span class="olog-relation">[Observe]</span> ethical dilemmas arising from computing. <span class="olog-relation">[Encode]</span> situations using concepts from ethical theory (stakeholders, harms, rights, duties). <span class="olog-relation">[Convolve]</span> case details (PATCH) with ethical frameworks (KERNEL) to reach normative conclusions. <span class="olog-relation">[Entangle]</span> technological possibilities with moral responsibilities. <span class="olog-relation">[Forget]</span> purely technical or ethically neutral descriptions of technology's impact.</p>
    </div>
    </div>
  </main>
  
  <footer>
    <p><a href="index.html">Back to Index</a></p>
  </footer>
</body>
</html>
