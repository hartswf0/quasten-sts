<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Noble STS</title>
    <link rel="stylesheet" href="style.css">
    <script src="script.js" defer></script>
</head>
<body>
    <div class="theme-toggle" id="themeToggle" title="Toggle Dark/Light Mode">
        ☀️
    </div>
    
    <div class="container">
        <header>
            <a href="index.html" class="back-link">← Back to Author Catalog</a>
            <h1>Noble STS</h1>
            <span class="tag sts">STS</span>
        </header>
        
        <div class="content">
            <h1>A Spencer-Brown Inspired Ontological Model of Noble's "Algorithms of Oppression"</h1>

This report presents a structured ontological index of Safiya Umoja Noble's influential 2018 work "Algorithms of Oppression: How Search Engines Reinforce Racism" using Spencer-Brown's calculus of distinctions. By marking entities as distinctions (◻) and relationships as indications (→), we create a formal representation that illuminates the conceptual architecture of algorithmic bias and its implications.

<h2>Foundational Entities and Primary Distinctions</h2>

<h3>Core Theoretical Constructs</h3>

◻ <strong>Algorithms of Oppression</strong>: Noble's 2018 book examining how search engines reinforce racism

◻ <strong>algorithmic oppression</strong>: Term coined by Noble to describe data failures specific to people of color, women, and marginalized groups[6]

◻ <strong>search engines</strong>: Primary technologies under examination, particularly Google

◻ <strong>technological redlining</strong>: Concept describing racial and gender-based profiling enacted by algorithms[11]

◻ <strong>data discrimination</strong>: Real social problem related to algorithmic bias[3]

◻ <strong>Google Search</strong>: Principal search engine analyzed in the book

◻ <strong>information monopoly</strong>: Google's dominant position in internet search and information retrieval[6]

<h3>Key Conceptual Frameworks</h3>

◻ <strong>Black intersectional feminist approach</strong>: The analytical framework Noble employs[6]

◻ <strong>algorithmic bias</strong>: The tendency of algorithms to reproduce social inequities[6]

◻ <strong>misrepresentation</strong>: How search results depict particular groups inaccurately[9]

◻ <strong>categorization</strong>: Process by which algorithms sort and classify information[6]

◻ <strong>big data optimism</strong>: The uncritical belief that data-driven solutions will solve social problems[6]

◻ <strong>racial and gender profiling</strong>: Practices embedded in algorithmic systems[3]

◻ <strong>right to be forgotten</strong>: European privacy concept contrasted with U.S. approaches[6]

<h2>Morphisms and Relational Structures</h2>

<h3>Foundational Relationships</h3>

◻ <strong>search engines</strong> → <em>reinforce</em> → ◻ <strong>racism</strong>
   <em>"Noble argues that search algorithms are racist and perpetuate societal problems"</em>[6]

◻ <strong>algorithms</strong> → <em>reflect and reproduce</em> → ◻ <strong>existing inequities</strong>
   <em>"While many new technological systems promote themselves as progressive and unbiased, Noble is arguing against this point"</em>[6]

◻ <strong>Google</strong> → <em>devalues</em> → ◻ <strong>Black women's identities</strong>
   <em>"Google's algorithm has maintained social inequalities and stereotypes for Black, Latina, and Asian women"</em>[6]

◻ <strong>algorithmic bias</strong> → <em>affects</em> → ◻ <strong>women of color disproportionately</strong>
   <em>"Noble argues that the combination of private interests...leads to a biased set of search algorithms that privilege whiteness and discriminate against people of color, specifically women of color"</em>[3]

◻ <strong>Google</strong> → <em>disclaims responsibility for</em> → ◻ <strong>search results</strong>
   <em>"Google has exacerbated racism and how they continue to deny responsibility for it"</em>[6]

<h3>Search Result Framework</h3>

◻ <strong>"Black girls" search</strong> → <em>returns</em> → ◻ <strong>pornographic content</strong>
   <em>"To her surprise, the results encompassed websites and images of porn"</em>[6]

◻ <strong>"white girls" search</strong> → <em>returns</em> → ◻ <strong>radically different results</strong>
   <em>"But, if you type in 'white girls,' the results are radically different"</em>[3]

◻ <strong>search algorithms</strong> → <em>privilege</em> → ◻ <strong>whiteness</strong>
   <em>"The suggested porn sites and un-moderated discussions about 'why Black women are so sassy' or 'why Black women are so angry' presents a disturbing portrait of Black womanhood"</em>[3]

◻ <strong>racist stereotypes</strong> → <em>are reinforced by</em> → ◻ <strong>algorithm results</strong>
   <em>"The first search results were common stereotypes of black girls, or the categories that Google created based on their own idea of a black girl"</em>[6]

<h2>Complex Conceptual Structures</h2>

<h3>Profit-Bias Framework</h3>

◻ <strong>Google</strong> → <em>is</em> → ◻ <strong>advertising company not information company</strong>
   <em>"Of course, Google Search is an advertising company, not a reliable information company"</em>[2]

◻ <strong>Google</strong> → <em>profits from</em> → ◻ <strong>racism and sexism</strong>
   <em>"How beneficial this is to the interests of Google as it profits from racism and sexism"</em>[2]

◻ <strong>advertising interests</strong> → <em>influence</em> → ◻ <strong>search results</strong>
   <em>"Google's results are biased, corrupted by a potent combination of advertising interests, Search Engine Optimization (SEO) techniques, and their corresponding neo-liberal values"</em>[1]

◻ <strong>commercial interests</strong> → <em>override</em> → ◻ <strong>information accuracy</strong>
   <em>"The combination of private interests in promoting certain sites, along with the monopoly status of a relatively small number of Internet search engines, leads to a biased set of search algorithms"</em>[9]

<h3>Case Study Framework</h3>

◻ <strong>Dylann Roof case</strong> → <em>demonstrates</em> → ◻ <strong>dangerous consequences of algorithmic bias</strong>
   <em>"Roof's repeated, frantic queries for 'black on white crime' generated a slew of slanted, inaccurate results from White supremacist and far-right sources"</em>[1]

◻ <strong>Roof</strong> → <em>received</em> → ◻ <strong>white supremacist sources instead of accurate information</strong>
   <em>"The author accuses Google of giving Roof the information and the ammunition he wanted—racist, anti-Black websites—rather than what he really needed"</em>[1]

◻ <strong>Kandis case</strong> → <em>illustrates</em> → ◻ <strong>economic consequences of algorithmic bias</strong>
   <em>"In the conclusion, 'Algorithms of Oppression,' she presents the story of Kandis, a Black hairdresser whose representation and business were both undermined by Yelp's biased advertising practices and searching strategies"</em>[1]

<h3>Neutrality Myth Framework</h3>

◻ <strong>technology</strong> → <em>is often presumed</em> → ◻ <strong>neutral and objective</strong>
   <em>"Many people regard Google as neutral, like a library"</em>[4]

◻ <strong>engineers</strong> → <em>embed</em> → ◻ <strong>personal biases in algorithms</strong>
   <em>"In her introduction, Noble details the various elements and public cases of sexual bias and harassment at Google"</em>[11]

◻ <strong>algorithms</strong> → <em>are portrayed as</em> → ◻ <strong>objective calculations</strong>
   <em>"For Noble, Google Search's algorithms are structured in a way that supports dominant narratives reflecting hegemonic frameworks"</em>[11]

◻ <strong>algorithmic objectivity</strong> → <em>masks</em> → ◻ <strong>human biases</strong>
   <em>"These codes are written by primarily white or Asian male engineers without any training in ethics or critical thinking"</em>[11]

<h2>Solutions Framework</h2>

<h3>Policy and Regulatory Approaches</h3>

◻ <strong>Noble</strong> → <em>advocates for</em> → ◻ <strong>public policies</strong>
   <em>"Noble appeals for public policies that will question big data optimism, stall Google's growing information monopoly, and regulate the filtering practices of commercial search engines"</em>[1]

◻ <strong>regulation</strong> → <em>should target</em> → ◻ <strong>information monopolies</strong>
   <em>"Public policies enacted by local and federal governments will reduce Google's 'information monopoly'"</em>[6]

◻ <strong>Noble</strong> → <em>calls on</em> → ◻ <strong>FCC and FTC</strong>
   <em>"She closes the chapter by calling upon the Federal Communications Commission (FCC) and the Federal Trade Commission (FTC) to 'regulate decency'"</em>[6]

◻ <strong>Noble</strong> → <em>rejects</em> → ◻ <strong>neoliberal solutions</strong>
   <em>"She critiques the complacent neoliberal solution for the lack of women and minorities in technology fields—more education and opportunities—which places the responsibility of progress on individuals rather than on those institutions subjugating them"</em>[1]

<h2>Conclusion</h2>

This Spencer-Brown inspired ontological model captures the rich theoretical framework of Safiya Umoja Noble's "Algorithms of Oppression." Through formal distinctions (◻) and indications (→), we visualize how Noble conceptualizes the ways search engines reinforce racism and sexism through seemingly neutral algorithms. The model highlights Noble's central argument that algorithmic bias is not merely a technical problem but a manifestation of structural oppression that requires regulatory intervention and critical examination of the power relations embedded in information technology.

Citations:
[1] https://digitalcommons.du.edu/cgi/viewcontent.cgi?article=1031&context=theliminal
[2] https://safiyaunoble.com/wp-content/uploads/2020/09/Algorithms_Oppression_Introduction_Intro.pdf
[3] https://rep.club/products/algorithms-of-oppression
[4] https://blogs.lse.ac.uk/impactofsocialsciences/2019/06/09/book-review-algorithms-of-oppression-how-search-engines-reinforce-racism-by-safiya-umoja-noble/
[5] https://www.youtube.com/watch?v=6KLTpoTpkXo
[6] https://en.wikipedia.org/wiki/Algorithms_of_Oppression
[7] https://annenberg.usc.edu/news/diversity-and-inclusion/algorithms-oppression-safiya-noble-finds-old-stereotypes-persist-new
[8] https://www.inclusionhub.com/articles/safiya-umoja-noble
[9] https://datasociety.net/library/safiya-umoja-noble-algorithms-of-oppression/
[10] https://www.democraticaudit.com/2019/06/29/book-review-algorithms-of-oppression-how-search-engines-reinforce-racism-by-safiya-umoja-noble/
[11] https://elischolar.library.yale.edu/cgi/viewcontent.cgi?article=1064&context=jcas

---
Answer from Perplexity: https://www.perplexity.ai/search/sts-ms-cat-core-26eOjT2rQjiRqIxKt6q3GA?utm_source=copy_output
        </div>
        
        <footer>
            <p>Part of the Reality Media Explorer project</p>
            <p>Created with STS_MS_CAT_CORE HTML Converter</p>
        </footer>
    </div>
</body>
</html>
